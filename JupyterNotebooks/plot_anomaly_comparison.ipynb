{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparing anomaly detection algorithms for outlier detection on toy datasets\n",
    "\n",
    "\n",
    "This example shows characteristics of different anomaly detection algorithms\n",
    "on 2D datasets. Datasets contain one or two modes (regions of high density)\n",
    "to illustrate the ability of algorithms to cope with multimodal data.\n",
    "\n",
    "For each dataset, 15% of samples are generated as random uniform noise. This\n",
    "proportion is the value given to the nu parameter of the OneClassSVM and the\n",
    "contamination parameter of the other outlier detection algorithms.\n",
    "Decision boundaries between inliers and outliers are displayed in black\n",
    "except for Local Outlier Factor (LOF) as it has no predict method to be applied\n",
    "on new data when it is used for outlier detection.\n",
    "\n",
    "The :class:`svm.OneClassSVM` is known to be sensitive to outliers and thus does\n",
    "not perform very well for outlier detection. This estimator is best suited for\n",
    "novelty detection when the training set is not contaminated by outliers.\n",
    "That said, outlier detection in high-dimension, or without any assumptions on\n",
    "the distribution of the inlying data is very challenging, and a One-class SVM\n",
    "might give useful results in these situations depending on the value of its\n",
    "hyperparameters.\n",
    "\n",
    ":class:`covariance.EllipticEnvelope` assumes the data is Gaussian and learns\n",
    "an ellipse. It thus degrades when the data is not unimodal. Notice however\n",
    "that this estimator is robust to outliers.\n",
    "\n",
    ":class:`ensemble.IsolationForest` and :class:`neighbors.LocalOutlierFactor`\n",
    "seem to perform reasonably well for multi-modal data sets. The advantage of\n",
    ":class:`neighbors.LocalOutlierFactor` over the other estimators is shown for\n",
    "the third data set, where the two modes have different densities. This\n",
    "advantage is explained by the local aspect of LOF, meaning that it only\n",
    "compares the score of abnormality of one sample with the scores of its\n",
    "neighbors.\n",
    "\n",
    "Finally, for the last data set, it is hard to say that one sample is more\n",
    "abnormal than another sample as they are uniformly distributed in a\n",
    "hypercube. Except for the :class:`svm.OneClassSVM` which overfits a little, all\n",
    "estimators present decent solutions for this situation. In such a case, it\n",
    "would be wise to look more closely at the scores of abnormality of the samples\n",
    "as a good estimator should assign similar scores to all the samples.\n",
    "\n",
    "While these examples give some intuition about the algorithms, this\n",
    "intuition might not apply to very high dimensional data.\n",
    "\n",
    "Finally, note that parameters of the models have been here handpicked but\n",
    "that in practice they need to be adjusted. In the absence of labelled data,\n",
    "the problem is completely unsupervised so model selection can be a challenge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'HomeCredit_columns_description2.csv', 'installments_payments.csv', 'Notebooks', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv', 'Zipped']\n"
     ]
    }
   ],
   "source": [
    "inputFile = 'C:\\\\Users\\\\momar\\\\OneDrive - Queen Mary, University of London\\\\MSc Project\\\\Home Credit Data' \n",
    "print(os.listdir(inputFile))\n",
    "app_train = pd.read_csv(inputFile + '\\\\application_train.csv')\n",
    "col = app_train['DAYS_EMPLOYED'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    make_blobs(centers=[[0, 0], [0, 0]], cluster_std=0.5,\n",
    "               **blobs_params)[0],\n",
    "    make_blobs(centers=[[2, 2], [-2, -2]], cluster_std=[0.5, 0.5],\n",
    "               **blobs_params)[0],\n",
    "    make_blobs(centers=[[2, 2], [-2, -2]], cluster_std=[1.5, .3],\n",
    "               **blobs_params)[0],\n",
    "    4. * (make_moons(n_samples=n_samples, noise=.05, random_state=0)[0] -\n",
    "          np.array([0.5, 0.25])),\n",
    "    14. * (np.random.RandomState(42).rand(n_samples, 2) - 0.5)]\n",
    "\n",
    "blobs_params = dict(random_state=0, n_samples=n_inliers, n_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (22500,2) and (1,1) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-50ac24d14cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# plot the levels lines and the points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"Local Outlier Factor\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# LOF does not implement predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\MScProject\\lib\\site-packages\\sklearn\\covariance\\outlier_detection.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mis_inlier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontamination\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mis_inlier\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\MScProject\\lib\\site-packages\\sklearn\\covariance\\outlier_detection.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X, raw_values)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'threshold_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mmahal_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmahal_dist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\MScProject\\lib\\site-packages\\sklearn\\covariance\\empirical_covariance_.py\u001b[0m in \u001b[0;36mmahalanobis\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mcentered_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobservations\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         mahalanobis_dist = np.sum(\n\u001b[1;32m--> 285\u001b[1;33m             np.dot(centered_obs, precision) * centered_obs, 1)\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmahalanobis_dist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (22500,2) and (1,1) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANoAAAAjCAYAAADygBQKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABEpJREFUeJztm1+IFVUcxz9f2yyi7Q9KIGapoNDmi7JEvfSHIpYNWoiIXVAQlkCTXnoKfIl6CyoIhOhB0oVK66Ul8qVQDGm1QPMfGKsttBj5kEYgrSv+ejgHu3u7d+fc2XvmXtbfBy6cM/ObmQ9n5nfPzJkzMjMcx8nLkk4LOM6tgCea41SAJ5rjVIAnmuNUgCea41SAJ5rjVEBhoknaLemKpBlJk5LerELMcRYTKT3aXuBvYAroA0Yk9eWUcpzFRkqizQAXgFkzuwZ8DgxltXKcRUZKoq0Efq+pT8dljuMk0pMQowbL/jdvS9IY8FKsLgWuLcCr3fQA1zstUYc7FdNtPgA3zKy31Y1SEm0aWFFTfxC4WB9kZluALQCSfjKz/lZlctFtPuBOKXSbDwSnMtul3Dr+CKwBbpe0FBgGxssczHFuVVISbQy4G1gPXAXOm9mZrFaOs8govHU0s5ES+/24xDY56TYfcKcUus0HSjrJv0dznPz4FCzHqYDSiSZpQNK5ZtOyJN0haV9cf1TS6oWItsnpDUlnJZ2U9J2khzvtVBP3siSTlHWULcVH0iuxnc5I+jSnT4qTpIckHZR0PJ67wcw+uyVdknS6yXpJ+jD6npS0qXCnZtbyD7gNOA+sJbwz+xnoq4t5DfgoloeBfWWO1WanZ4C7Ynl7NzjFuF7gMDAB9He4jdYBx4H7Y/2BTrcR4bloeyz3AVOZnZ4ENgGnm6wfBA4Q3jE/Dhwt2mfZHu0xYNLMLljzaVlDwJ5Y/hJ4VlKjl9/totDJzA6a2dVYnSC8E8xJSjsBvAO8C/zTBT6vArvM7DKAmV3qAicD7onle2nwHredmNlh4M95QoaAvRaYAO6TtGKe+NKJthL4rabeaFrWzRgzuw78BSwrebx2OdUySvhXykmhk6SNwCoz+zqzS5IP4TXOeklHJE1IGugCp7eAzZKmgW+A1zM7FdHqtZY0M6QRKdOykqZutZHk40naDPQDT2X0gQInSUuAD4CtmT2SfCI9hNvHpwk9/veSNpjZlQ46jQCfmNl7kp4AxqLTjUxORbR8bZft0aaBVTX1RtOybsZI6iF0+fN1xwslxQlJzwE7gRfNbCajT4pTL7ABOCRpinC/P55xQCT1vH1lZrNm9itwjpB4uUhxGgX2A5jZD8CdwPKMTkUkXWtzKPmw2EP4dGYN/z3APloXs4O5gyH7Mz/ApjhtJDx4r8vp0opTXfwh8g6GpLTRALAnlpcTbpGWddjpALA1lh+JF7Uyn7vVNB8MeYG5gyHHCve3AJFB4Jd44e6My94m9BQQ/nW+ACaBY8DanA2T6PQt8AdwIv7GO+1UF5s10RLbSMD7wFngFDDc6TYijDQeiUl4Ang+s89nhE/DZgm91yiwDdhW00a7ou+plHPmM0McpwJ8ZojjVIAnmuNUgCea41SAJ5rjVIAnmuNUgCea41SAJ5rjVIAnmuNUwL+X7fqP8vMN7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "#         Albert Thomas <albert.thomas@telecom-paristech.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "matplotlib.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "# Example settings\n",
    "n_samples = 300\n",
    "outliers_fraction = 0.15\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "n_inliers = n_samples - n_outliers\n",
    "\n",
    "# define outlier/anomaly detection methods to be compared\n",
    "anomaly_algorithms = [\n",
    "    (\"Robust covariance\", EllipticEnvelope(contamination=outliers_fraction)),\n",
    "    (\"One-Class SVM\", svm.OneClassSVM(nu=outliers_fraction, kernel=\"rbf\",\n",
    "                                      gamma=0.1)),\n",
    "    (\"Isolation Forest\", IsolationForest(contamination=outliers_fraction,\n",
    "                                         random_state=42)),\n",
    "    (\"Local Outlier Factor\", LocalOutlierFactor(\n",
    "        n_neighbors=35, contamination=outliers_fraction))]\n",
    "\n",
    "# Define datasets\n",
    "\n",
    "\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 150),\n",
    "                     np.linspace(-7, 7, 150))\n",
    "\n",
    "plt.figure(figsize=(len(anomaly_algorithms) * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X = col.reshape(-1,1)\n",
    "\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "    t0 = time.time()\n",
    "    algorithm.fit(X)\n",
    "    t1 = time.time()\n",
    "    plt.subplot(len(X), len(anomaly_algorithms), plot_num)\n",
    "    #if i_dataset == 0:\n",
    "    #    plt.title(name, size=18)\n",
    "\n",
    "    # fit the data and tag outliers\n",
    "    if name == \"Local Outlier Factor\":\n",
    "        y_pred = algorithm.fit_predict(X)\n",
    "    else:\n",
    "        y_pred = algorithm.fit(X).predict(X)\n",
    "\n",
    "    # plot the levels lines and the points\n",
    "    if name != \"Local Outlier Factor\":  # LOF does not implement predict\n",
    "        Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00'])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[(y_pred + 1) // 2])\n",
    "\n",
    "    plt.xlim(-7, 7)\n",
    "    plt.ylim(-7, 7)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
