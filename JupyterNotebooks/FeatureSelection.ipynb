{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50b106bf0350e3bbf749b2b7c884f61d7e2bb362"
   },
   "source": [
    "# Feature Selection \n",
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectFromModel, chi2, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6457fd9bc6d93c2a2d5bdeeb7d8e92e5a4df5f61"
   },
   "source": [
    "### Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ec925c8bae03e83580c84f3cfbac13fc0610d830"
   },
   "outputs": [],
   "source": [
    "def take_sample(df, sampling_ratio):\n",
    "    application_sample1 = df.loc[df.TARGET==1].sample(sampling_ratio=sampling_ratio, replace=False)\n",
    "    print('label 1 sample size:', str(application_sample1.shape[0]))\n",
    "    application_sample0 = df.loc[df.TARGET==0].sample(sampling_ratio=sampling_ratio, replace=False)\n",
    "    print('label 0 sample size:', str(application_sample0.shape[0]))\n",
    "    return pd.concat([application_sample1, application_sample0], axis=0).sort_values('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set folder paths for getting input and saving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9c2223e87930b2b0edd472bf837c332fc64c7073"
   },
   "outputs": [],
   "source": [
    "def setupFolderPaths():    \n",
    "    #Set input data folder \n",
    "    dataFolder = os.getcwd() + os.sep + os.pardir + os.sep + 'ProjectDataFiles'\n",
    "    if(not os.path.exists(dataFolder)):\n",
    "        print(\"Input Data folder not found. Please specify data folder path as dataFolder variable to proceed\")\n",
    "        raise NotADirectoryError\n",
    "\n",
    "    #Create output folder is it does not exist\n",
    "    outputFolder = os.getcwd() + os.sep + os.pardir + os.sep + 'CodeOutputs'\n",
    "\n",
    "    if not os.path.exists(outputFolder):\n",
    "        os.makedirs(outputFolder)\n",
    "        print('Output Folder created')\n",
    "        \n",
    "    return dataFolder, outputFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8d211c6cb0ea998bfb9d25f795a3a1acb001baa2"
   },
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    if(not os.path.exists(fileName)):\n",
    "        raise FileNotFoundError\n",
    "        \n",
    "    return pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace outliers in input data\n",
    "def replace_outliers(df):\n",
    "    #Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    if 'CODE_GENDER' in df:\n",
    "        df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "    #Replace outlier values with nan\n",
    "    df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: x if x <= 0 else np.nan)\n",
    "    df['REGION_RATING_CLIENT_W_CITY'] = df['REGION_RATING_CLIENT_W_CITY'].map(lambda x: x if x >= 0 else np.nan)\n",
    "    df['AMT_INCOME_TOTAL'] = df['AMT_INCOME_TOTAL'].map(lambda x: x if x <= 1e8 else np.nan)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_QRT'] = df['AMT_REQ_CREDIT_BUREAU_QRT'].map(lambda x: x if x <= 10 else np.nan)\n",
    "    df['OBS_30_CNT_SOCIAL_CIRCLE'] = df['OBS_30_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 40 else np.nan)\n",
    "    df['OBS_60_CNT_SOCIAL_CIRCLE'] = df['OBS_60_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 50 else np.nan)\n",
    "    df['DEF_30_CNT_SOCIAL_CIRCLE'] = df['DEF_30_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 100 else np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to identify feature types in a given data frame\n",
    "def identify_feature_types(df, features_to_ignore):\n",
    "    categorical_features = list(f for f in df.select_dtypes(include='object') if f not in features_to_ignore)\n",
    "    floatingPoint_features = list(f for f in df.select_dtypes(include='float64') if f not in features_to_ignore)\n",
    "    temp = list(f for f in df.select_dtypes(include='int64') if f not in features_to_ignore)\n",
    "    bool_features = [x for x in temp if 'FLAG' in x]\n",
    "    integer_features = [x for x in temp if x not in bool_features]\n",
    "    totalCount = len(categorical_features) + len(floatingPoint_features) + len(bool_features) + len(integer_features)\n",
    "    print ('Catagorical Features : {}, Floating Point Features : {}, Boolean Features : {}, Integer Features : {}, Total Count : {}'\n",
    "       .format(len(categorical_features), len(floatingPoint_features), len(bool_features), len(integer_features), totalCount))\n",
    "    \n",
    "    return categorical_features, floatingPoint_features, bool_features, integer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df, feature_list, scale_range = (0,1)):\n",
    "    #Scale each feature to 0-1\n",
    "    scaler = MinMaxScaler(feature_range = scale_range)\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        scaler.fit(df[feature].values.reshape(-1,1))\n",
    "        df[feature] = scaler.transform(df[feature].values.reshape(-1,1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(df, feature_list, imputeMode = 'median'):\n",
    "    #Imputer for numerical features\n",
    "    imputer = Imputer(strategy = imputeMode)\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        imputer.fit(df[feature].values.reshape(-1,1))\n",
    "        df[feature] = imputer.transform(df[feature].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8fc1c57326e3f8d12c24a27167164f1d7509a03b"
   },
   "outputs": [],
   "source": [
    "dataFolder, outputFolder = setupFolderPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catagorical Features : 16, Floating Point Features : 66, Boolean Features : 26, Integer Features : 12, Total Count : 120\n"
     ]
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "for cat_feature in categorical_feats:\n",
    "    input_df[cat_feature] = input_df[cat_feature].fillna(input_df[cat_feature].value_counts().index[0])\n",
    "    \n",
    "input_df = impute_features(input_df, integer_feats + floatingPoint_feats)\n",
    "#input_df = scale_features(input_df, integer_feats + floatingPoint_feats)\n",
    "    \n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = input_df.pop('TARGET')\n",
    "input_df_ids = input_df.pop('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307507 entries, 0 to 307510\n",
      "Columns: 243 entries, CNT_CHILDREN to EMERGENCYSTATE_MODE_Yes\n",
      "dtypes: float64(78), int64(165)\n",
      "memory usage: 572.4 MB\n"
     ]
    }
   ],
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9e931811c3f182ed852bca050c64dd9bf6ad608"
   },
   "source": [
    "# <a id='2'>Feature Selection</a>\n",
    "- select **100** features from 226\n",
    "- **xxx_support**: list to represent select this feature or not\n",
    "- **xxx_feature**: the name of selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "046388ce3e7a77c033bd8cd2fb1c7c8859c43a75"
   },
   "source": [
    "## <a id='2-1'>1 Filter</a>\n",
    "- documentation for **SelectKBest**: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "###  <a id='2-1-1'>1.1 Pearson Correlation</a>\n",
    "**Note**\n",
    "- Normalization: no\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "cfcbd8200acaedfffa677892bf63e05194172bca"
   },
   "outputs": [],
   "source": [
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-10:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in X.columns]\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "b85b3e3c49375e6a9c0a8690774277168d91fd8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 selected features\n"
     ]
    }
   ],
   "source": [
    "cor_support, cor_feature = cor_selector(input_df, labels)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cbcc0cb047f4071859c51b69cd059f254b72a2e"
   },
   "source": [
    "###  <a id='2-1-2'>1.2 Chi-2</a>\n",
    "\n",
    "**Note**\n",
    "- Normalization: MinMaxScaler (values should be bigger than 0)\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "658683b50f43f019545b99bd67efe6546c91774d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=150, score_func=<function chi2 at 0x000001AB835C0730>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = scale_features(input_df, integer_feats + floatingPoint_feats)\n",
    "chi_selector = SelectKBest(chi2, k=150)\n",
    "chi_selector.fit(input_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "c98cd7a868bdd777997e6c3e6781b71a8e74426b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 selected features\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efb3ef018eef869665dbdb9efc87bb19c497a281"
   },
   "source": [
    "## <a id='2-2'>2. Wrapper</a>\n",
    "- documentation for **RFE**: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "**Note**\n",
    "- Normalization: depend on the used model; yes for LR\n",
    "- Impute missing values: depend on the used model; yes for LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "a9abf1b048e97c650a70b90abf14b7a4b2d1289c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 153 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=150, step=10, verbose=15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_selector = RFE(estimator=LogisticRegression(solver='saga', n_jobs=-1), n_features_to_select=150, step=10, verbose=15)\n",
    "rfe_selector.fit(input_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "053eec2922e6d3dab12c33dd7d32541c92f7baf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 selected features\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-1f94942980f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrfe_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrfe_support\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'selected features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\MScProject\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = input_df.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')\n",
    "#predicted = rfe_selector.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3eb1a94581cd812889393d761578502c261eabd"
   },
   "source": [
    "## <a id='2-3'>3. Embeded</a>\n",
    "- documentation for **SelectFromModel**: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
    "###  <a id='2-3-1'>3.1 Logistics Regression L1</a>\n",
    "**Note**\n",
    "- Normalization: Yes\n",
    "- Impute missing values: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "76dab473b86f2179c3fe19dd92a340fd44a32391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='1.25*median')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median')\n",
    "embeded_lr_selector.fit(input_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "c06bd778b9d570ff59643421aca6b5958f440f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = input_df.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c58b2e9fec43aae9139f60a4d1e281bd02b858a4"
   },
   "source": [
    "###  <a id='2-3-2'>3.2 Random Forest</a>\n",
    "**Note**\n",
    "- Normalization: No\n",
    "- Impute missing values: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "b6dca212430308787824918cd0de78926747b7e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold='1.25*median')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=150), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(input_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "9367e5e5afe37ae279966eb01ebfa2b1a6dd970f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = input_df.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3848e7fb4720bdec1626779dc1f54a298ed0c10a"
   },
   "source": [
    "###  <a id='2-3-3'>3.3 LightGBM</a>\n",
    "**Note**\n",
    "- Normalization: No\n",
    "- Impute missing values: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "a82078ce64a76d38676ca621eef99afd5f0fb3e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 2.0250000e+05, 4.0659750e+05, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 2.7000000e+05, 1.2935025e+06, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 6.7500000e+04, 1.3500000e+05, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00, 1.5300000e+05, 6.7766400e+05, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.7100000e+05, 3.7010700e+05, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.5750000e+05, 6.7500000e+05, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_selector = VarianceThreshold(0.01)\n",
    "var_selector.fit_transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "a0e8713cd2980151d14c9c67334e92628226362c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 selected features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_feature = input_df.loc[:,var_support].columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f8eb0e93217e114442931ce30a2657926e471b1"
   },
   "source": [
    "# <a id='3'>Summary</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_uuid": "457ed42ac4708f6f93bb23c194e6cc7d17b71333"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':input_df.columns, 'Variance': var_support, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, \n",
    "                                     'Random Forest':embeded_rf_support})\n",
    "## count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "top100 = feature_selection_df.head(100).Feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_df = input_df[top100]\n",
    "#len(labels)\n",
    "#input_df['TARGET'] = labels\n",
    "input_df.to_csv(outputFolder + '\\\\DataSetVersion6_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
