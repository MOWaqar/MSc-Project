{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "#memory management\n",
    "import gc\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#to impute missing values\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectFromModel, chi2, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "### Set folder paths for getting input and saving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupFolderPaths():    \n",
    "    #Set input data folder \n",
    "    dataFolder = os.getcwd() + os.sep + os.pardir + os.sep + 'ProjectDataFiles'\n",
    "    if(not os.path.exists(dataFolder)):\n",
    "        print(\"Input Data folder not found. Please specify data folder path as dataFolder variable to proceed\")\n",
    "        raise NotADirectoryError\n",
    "\n",
    "    #Create output folder is it does not exist\n",
    "    outputFolder = os.getcwd() + os.sep + os.pardir + os.sep + 'CodeOutputs'\n",
    "\n",
    "    if not os.path.exists(outputFolder):\n",
    "        os.makedirs(outputFolder)\n",
    "        print('Output Folder created')\n",
    "        \n",
    "    return dataFolder, outputFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    if(not os.path.exists(fileName)):\n",
    "        raise FileNotFoundError\n",
    "        \n",
    "    return pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the outliers in the input data set with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace outliers in input data\n",
    "def replace_outliers(df):\n",
    "    #Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    if 'CODE_GENDER' in df:\n",
    "        df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "    #Replace outlier values with nan\n",
    "    df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: x if x <= 0 else np.nan)\n",
    "    df['REGION_RATING_CLIENT_W_CITY'] = df['REGION_RATING_CLIENT_W_CITY'].map(lambda x: x if x >= 0 else np.nan)\n",
    "    df['AMT_INCOME_TOTAL'] = df['AMT_INCOME_TOTAL'].map(lambda x: x if x <= 5e6 else np.nan)\n",
    "    df['AMT_REQ_CREDIT_BUREAU_QRT'] = df['AMT_REQ_CREDIT_BUREAU_QRT'].map(lambda x: x if x <= 10 else np.nan)\n",
    "    df['OBS_30_CNT_SOCIAL_CIRCLE'] = df['OBS_30_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 40 else np.nan)\n",
    "    df['OBS_60_CNT_SOCIAL_CIRCLE'] = df['OBS_60_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 50 else np.nan)\n",
    "    df['DEF_30_CNT_SOCIAL_CIRCLE'] = df['DEF_30_CNT_SOCIAL_CIRCLE'].map(lambda x: x if x <= 100 else np.nan)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Feature types : Catagorical, Numerical, Integer and Boolean (Flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to identify feature types in a given data frame\n",
    "def identify_feature_types(df, features_to_ignore, verbose = False):\n",
    "    categorical_features = list(f for f in df.select_dtypes(include='object') if f not in features_to_ignore)\n",
    "    floatingPoint_features = list(f for f in df.select_dtypes(include='float64') if f not in features_to_ignore)\n",
    "    temp = list(f for f in df.select_dtypes(include='int64') if f not in features_to_ignore)\n",
    "    bool_features = [x for x in temp if 'FLAG' in x]\n",
    "    integer_features = [x for x in temp if x not in bool_features]\n",
    "    totalCount = len(categorical_features) + len(floatingPoint_features) + len(bool_features) + len(integer_features)\n",
    "    if (verbose == True):\n",
    "        print ('Catagorical Features : {}, Floating Point Features : {}, Boolean Features : {}, Integer Features : {}, Total Count : {}'\n",
    "           .format(len(categorical_features), len(floatingPoint_features), len(bool_features), len(integer_features), totalCount))\n",
    "    \n",
    "    return categorical_features, floatingPoint_features, bool_features, integer_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop list of features from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df, features):\n",
    "    df = df.drop(columns=[f for f in df.columns if f in features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df, feature_list = None, scale_range = (0,1)):\n",
    "    if(feature_list == None):\n",
    "        feature_list = [f for f in df.columns if f not in ['TARGET', 'SK_ID_CURR', 'Unnamed :0']]\n",
    "        \n",
    "    #Scale each feature to 0-1\n",
    "    scaler = MinMaxScaler(feature_range = scale_range)\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        if (df[feature].dtype == 'object'):\n",
    "            continue\n",
    "\n",
    "        scaler.fit(df[feature].values.reshape(-1,1))\n",
    "        df[feature] = scaler.transform(df[feature].values.reshape(-1,1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(df, features = 'All'):\n",
    "    categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "    if(features == 'All'):\n",
    "        feature_list = [f for f in df.columns if f not in ['TARGET', 'SK_ID_CURR', 'Unnamed :0']]\n",
    "    elif(features == 'Numerical'):\n",
    "        feature_list = floatingPoint_feats + integer_feats\n",
    "    elif(features == 'Categorical'):\n",
    "        feature_list = categorical_feats + bool_feats\n",
    "    else:\n",
    "        raise ValueError('features can either be All, Numerical, Categorical')\n",
    "        \n",
    "    #Imputer for numerical features\n",
    "    imputer = Imputer(strategy = 'median')\n",
    "    \n",
    "    for feature in feature_list:\n",
    "        if (feature in categorical_feats + bool_feats):\n",
    "            df[feature] = df[feature].fillna(df[feature].value_counts().index[0])\n",
    "        else:\n",
    "            imputer.fit(df[feature].values.reshape(-1,1))\n",
    "            df[feature] = imputer.transform(df[feature].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to caluculate WOE\n",
    "def calculate_WOE(df, target,feature):\n",
    "    lst = []\n",
    "    for i in range(df[feature].nunique(dropna=False)):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (target == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (target == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "\n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Variance Selector\n",
    "**Note**\n",
    "- Scaling: no\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_selector(input_df, threshold = 0.01):\n",
    "    df = input_df.copy()\n",
    "    df = impute_features(df)\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit_transform(df)\n",
    "    var_support = selector.get_support()\n",
    "    var_feature = df.loc[:,var_support].columns.tolist()\n",
    "    print('Variance : ', str(len(var_feature)), 'selected features out of', str(len(var_support)))\n",
    "    del df, selector, var_feature\n",
    "    return var_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pearson Correlation Selector\n",
    "**Note**\n",
    "- Scaling: no\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(input_df, labels, drop_ratio = 0.5):\n",
    "    drop_ratio = max(0,min(drop_ratio, 1))\n",
    "    df = input_df.copy()\n",
    "    cor_list = []\n",
    "    df = impute_features(df, 'All')\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in df.columns.tolist():\n",
    "        cor = np.corrcoef(df[i], labels)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = df.iloc[:,np.argsort(np.abs(cor_list))[-int(len(cor_list) * drop_ratio):]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in df.columns]\n",
    "    print('Pearson : ', str(len(cor_feature)), 'selected features out of', str(len(cor_support)))\n",
    "    del df, cor_feature\n",
    "    return cor_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Chi2 Selector\n",
    "**Note**\n",
    "- Scaling: yes\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_selector(input_df, labels, drop_ratio = 0.5):\n",
    "    drop_ratio = max(0,min(drop_ratio, 1))\n",
    "    df = input_df.copy()\n",
    "    num_feats = int(len(df.columns) * drop_ratio)\n",
    "    df = impute_features(df, features ='All')    \n",
    "    df = scale_features(df)\n",
    "    selector = SelectKBest(chi2, k=num_feats)\n",
    "    selector.fit(df, labels)\n",
    "    chi_support = selector.get_support()\n",
    "    chi_feature = df.loc[:,chi_support].columns.tolist()\n",
    "    print('CHI2 : ', str(len(chi_feature)), 'selected features out of', str(len(chi_support)))\n",
    "    del df, selector, chi_feature\n",
    "    return chi_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RFE Selector\n",
    "**Note**\n",
    "- Scaling: yes\n",
    "- Impute missing values: yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_selector(input_df, labels, drop_ratio = 0.5):\n",
    "    drop_ratio = max(0,min(drop_ratio, 1))\n",
    "    df = input_df.copy()\n",
    "    num_feats = int(len(df.columns) * drop_ratio)\n",
    "    df = impute_features(df, features ='All')    \n",
    "    df = scale_features(df)\n",
    "    selector = RFE(estimator=LogisticRegression(solver='saga', n_jobs=-1), n_features_to_select=num_feats, step=10, verbose=20)\n",
    "    selector.fit(df, labels)\n",
    "    rfe_support = selector.get_support()\n",
    "    rfe_feature = df.loc[:,rfe_support].columns.tolist()\n",
    "    print('RFE : ', str(len(rfe_feature)), 'selected features out of', str(len(rfe_feature)))\n",
    "    del df, selector, rfe_feature\n",
    "    return rfe_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Random Forest Selector\n",
    "**Note**\n",
    "- Scaling: no\n",
    "- Impute missing values: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_selector(input_df, labels, drop_ratio = 0.5):\n",
    "    drop_ratio = max(0,min(drop_ratio, 1))\n",
    "    df = input_df.copy()\n",
    "    num_feats = int(len(df.columns) * drop_ratio)\n",
    "    df = impute_features(df, features ='All')\n",
    "    selector = SelectFromModel(RandomForestClassifier(n_estimators=150), threshold='1.25*median')\n",
    "    selector.fit(df, labels)\n",
    "    rf_support = selector.get_support()\n",
    "    rf_feature = df.loc[:,rf_support].columns.tolist()\n",
    "    print('RF : ', str(len(rf_support)), 'selected features out of', str(len(rf_feature)))\n",
    "    del df, selector, rf_feature\n",
    "    return rf_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(input_df, labels, min_votes = 3, drop_ratio = 0.5):\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    \n",
    "    var_support = var_selector(df)\n",
    "    cor_support = cor_selector(df, labels, drop_ratio)\n",
    "    chi_support = chi_selector(df, labels, drop_ratio)\n",
    "    rfe_support = rfe_selector(df, labels, drop_ratio)\n",
    "    rf_support = rf_selector(df, labels, drop_ratio)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "    # put all selection together\n",
    "    feature_selection_df = pd.DataFrame({'Feature':df.columns, 'Variance': var_support, 'Pearson':cor_support,\n",
    "                                         'Chi-2':chi_support, 'RFE':rfe_support, 'Random Forest':rf_support})\n",
    "    ## count the selected times for each feature\n",
    "    feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "    # display the top 100\n",
    "    feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "    \n",
    "    feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "    \n",
    "    del df, var_support, cor_support, chi_support, rfe_support, rf_support\n",
    "    \n",
    "    return feature_selection_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_sample(df, labels, stratified = True):\n",
    "    df['TARGET'] = labels\n",
    "    num_samples = df.loc[df.TARGET==1].shape[0]\n",
    "    if (stratified):\n",
    "        sampling_ratio = num_samples / df.shape[0]\n",
    "        sample1 = df.loc[df.TARGET==1].sample(frac=sampling_ratio, replace=False)\n",
    "        print('label 1 sample size:', str(sample1.shape[0]))\n",
    "        sample0 = df.loc[df.TARGET==0].sample(frac=sampling_ratio, replace=False)\n",
    "        print('label 0 sample size:', str(sample0.shape[0]))\n",
    "    else:\n",
    "        sample1 = df.loc[df.TARGET==1].sample(n=num_samples, replace=False)\n",
    "        print('label 1 sample size:', str(sample1.shape[0]))\n",
    "        sample0 = df.loc[df.TARGET==0].sample(n=num_samples, replace=False)\n",
    "        print('label 0 sample size:', str(sample0.shape[0]))\n",
    "    \n",
    "    sampled_df = pd.concat([sample1, sample0], axis=0)\n",
    "    sampled_labels = sampled_df.pop('TARGET')\n",
    "    return sampled_df, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder, outputFolder = setupFolderPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set version 1: with missing values as NaN\n",
    "### Data set version 1_a: Null values without categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307507 entries, 0 to 307510\n",
      "Data columns (total 80 columns):\n",
      "SK_ID_CURR                      307507 non-null int64\n",
      "TARGET                          307507 non-null int64\n",
      "CNT_CHILDREN                    307507 non-null int64\n",
      "AMT_INCOME_TOTAL                307502 non-null float64\n",
      "AMT_CREDIT                      307507 non-null float64\n",
      "AMT_ANNUITY                     307495 non-null float64\n",
      "AMT_GOODS_PRICE                 307229 non-null float64\n",
      "REGION_POPULATION_RELATIVE      307507 non-null float64\n",
      "DAYS_BIRTH                      307507 non-null int64\n",
      "DAYS_EMPLOYED                   252133 non-null float64\n",
      "DAYS_REGISTRATION               307507 non-null float64\n",
      "DAYS_ID_PUBLISH                 307507 non-null int64\n",
      "OWN_CAR_AGE                     104580 non-null float64\n",
      "CNT_FAM_MEMBERS                 307505 non-null float64\n",
      "REGION_RATING_CLIENT            307507 non-null int64\n",
      "REGION_RATING_CLIENT_W_CITY     307507 non-null int64\n",
      "HOUR_APPR_PROCESS_START         307507 non-null int64\n",
      "REG_REGION_NOT_LIVE_REGION      307507 non-null int64\n",
      "REG_REGION_NOT_WORK_REGION      307507 non-null int64\n",
      "LIVE_REGION_NOT_WORK_REGION     307507 non-null int64\n",
      "REG_CITY_NOT_LIVE_CITY          307507 non-null int64\n",
      "REG_CITY_NOT_WORK_CITY          307507 non-null int64\n",
      "LIVE_CITY_NOT_WORK_CITY         307507 non-null int64\n",
      "EXT_SOURCE_1                    134131 non-null float64\n",
      "EXT_SOURCE_2                    306847 non-null float64\n",
      "EXT_SOURCE_3                    246542 non-null float64\n",
      "APARTMENTS_AVG                  151447 non-null float64\n",
      "BASEMENTAREA_AVG                127565 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_AVG     157501 non-null float64\n",
      "YEARS_BUILD_AVG                 103021 non-null float64\n",
      "COMMONAREA_AVG                  92645 non-null float64\n",
      "ELEVATORS_AVG                   143617 non-null float64\n",
      "ENTRANCES_AVG                   152680 non-null float64\n",
      "FLOORSMAX_AVG                   154488 non-null float64\n",
      "FLOORSMIN_AVG                   98867 non-null float64\n",
      "LANDAREA_AVG                    124919 non-null float64\n",
      "LIVINGAPARTMENTS_AVG            97310 non-null float64\n",
      "LIVINGAREA_AVG                  153158 non-null float64\n",
      "NONLIVINGAPARTMENTS_AVG         93995 non-null float64\n",
      "NONLIVINGAREA_AVG               137827 non-null float64\n",
      "APARTMENTS_MODE                 151447 non-null float64\n",
      "BASEMENTAREA_MODE               127565 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MODE    157501 non-null float64\n",
      "YEARS_BUILD_MODE                103021 non-null float64\n",
      "COMMONAREA_MODE                 92645 non-null float64\n",
      "ELEVATORS_MODE                  143617 non-null float64\n",
      "ENTRANCES_MODE                  152680 non-null float64\n",
      "FLOORSMAX_MODE                  154488 non-null float64\n",
      "FLOORSMIN_MODE                  98867 non-null float64\n",
      "LANDAREA_MODE                   124919 non-null float64\n",
      "LIVINGAPARTMENTS_MODE           97310 non-null float64\n",
      "LIVINGAREA_MODE                 153158 non-null float64\n",
      "NONLIVINGAPARTMENTS_MODE        93995 non-null float64\n",
      "NONLIVINGAREA_MODE              137827 non-null float64\n",
      "APARTMENTS_MEDI                 151447 non-null float64\n",
      "BASEMENTAREA_MEDI               127565 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MEDI    157501 non-null float64\n",
      "YEARS_BUILD_MEDI                103021 non-null float64\n",
      "COMMONAREA_MEDI                 92645 non-null float64\n",
      "ELEVATORS_MEDI                  143617 non-null float64\n",
      "ENTRANCES_MEDI                  152680 non-null float64\n",
      "FLOORSMAX_MEDI                  154488 non-null float64\n",
      "FLOORSMIN_MEDI                  98867 non-null float64\n",
      "LANDAREA_MEDI                   124919 non-null float64\n",
      "LIVINGAPARTMENTS_MEDI           97310 non-null float64\n",
      "LIVINGAREA_MEDI                 153158 non-null float64\n",
      "NONLIVINGAPARTMENTS_MEDI        93995 non-null float64\n",
      "NONLIVINGAREA_MEDI              137827 non-null float64\n",
      "TOTALAREA_MODE                  159077 non-null float64\n",
      "OBS_30_CNT_SOCIAL_CIRCLE        306484 non-null float64\n",
      "DEF_30_CNT_SOCIAL_CIRCLE        306486 non-null float64\n",
      "OBS_60_CNT_SOCIAL_CIRCLE        306485 non-null float64\n",
      "DEF_60_CNT_SOCIAL_CIRCLE        306486 non-null float64\n",
      "DAYS_LAST_PHONE_CHANGE          307506 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR      265988 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_DAY       265988 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK      265988 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON       265988 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_QRT       265986 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR      265988 non-null float64\n",
      "dtypes: float64(66), int64(14)\n",
      "memory usage: 190.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Version one with null values included and no categorical features.\n",
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = drop_features(input_df, categorical_feats + bool_feats)\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 1_b: Null values with categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307507 entries, 0 to 307510\n",
      "Columns: 261 entries, SK_ID_CURR to EMERGENCYSTATE_MODE_nan\n",
      "dtypes: float64(66), int64(195)\n",
      "memory usage: 614.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "\n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64, dummy_na= True)\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 1_c: Null values with categorical feature WOE encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307507 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(82), int64(40)\n",
      "memory usage: 288.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "for cat_feature in categorical_feats:\n",
    "    WoE_df = calculate_WOE(input_df, 'TARGET', cat_feature)\n",
    "    input_df[cat_feature] = input_df[cat_feature].replace(WoE_df.set_index('Value')['WoE'])\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats, WoE_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set version 2: With missing value entries omitted\n",
    "### Data set version 2_a: Without categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10745 entries, 71 to 307482\n",
      "Data columns (total 80 columns):\n",
      "SK_ID_CURR                      10745 non-null int64\n",
      "TARGET                          10745 non-null int64\n",
      "CNT_CHILDREN                    10745 non-null int64\n",
      "AMT_INCOME_TOTAL                10745 non-null float64\n",
      "AMT_CREDIT                      10745 non-null float64\n",
      "AMT_ANNUITY                     10745 non-null float64\n",
      "AMT_GOODS_PRICE                 10745 non-null float64\n",
      "REGION_POPULATION_RELATIVE      10745 non-null float64\n",
      "DAYS_BIRTH                      10745 non-null int64\n",
      "DAYS_EMPLOYED                   10745 non-null float64\n",
      "DAYS_REGISTRATION               10745 non-null float64\n",
      "DAYS_ID_PUBLISH                 10745 non-null int64\n",
      "OWN_CAR_AGE                     10745 non-null float64\n",
      "CNT_FAM_MEMBERS                 10745 non-null float64\n",
      "REGION_RATING_CLIENT            10745 non-null int64\n",
      "REGION_RATING_CLIENT_W_CITY     10745 non-null int64\n",
      "HOUR_APPR_PROCESS_START         10745 non-null int64\n",
      "REG_REGION_NOT_LIVE_REGION      10745 non-null int64\n",
      "REG_REGION_NOT_WORK_REGION      10745 non-null int64\n",
      "LIVE_REGION_NOT_WORK_REGION     10745 non-null int64\n",
      "REG_CITY_NOT_LIVE_CITY          10745 non-null int64\n",
      "REG_CITY_NOT_WORK_CITY          10745 non-null int64\n",
      "LIVE_CITY_NOT_WORK_CITY         10745 non-null int64\n",
      "EXT_SOURCE_1                    10745 non-null float64\n",
      "EXT_SOURCE_2                    10745 non-null float64\n",
      "EXT_SOURCE_3                    10745 non-null float64\n",
      "APARTMENTS_AVG                  10745 non-null float64\n",
      "BASEMENTAREA_AVG                10745 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_AVG     10745 non-null float64\n",
      "YEARS_BUILD_AVG                 10745 non-null float64\n",
      "COMMONAREA_AVG                  10745 non-null float64\n",
      "ELEVATORS_AVG                   10745 non-null float64\n",
      "ENTRANCES_AVG                   10745 non-null float64\n",
      "FLOORSMAX_AVG                   10745 non-null float64\n",
      "FLOORSMIN_AVG                   10745 non-null float64\n",
      "LANDAREA_AVG                    10745 non-null float64\n",
      "LIVINGAPARTMENTS_AVG            10745 non-null float64\n",
      "LIVINGAREA_AVG                  10745 non-null float64\n",
      "NONLIVINGAPARTMENTS_AVG         10745 non-null float64\n",
      "NONLIVINGAREA_AVG               10745 non-null float64\n",
      "APARTMENTS_MODE                 10745 non-null float64\n",
      "BASEMENTAREA_MODE               10745 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MODE    10745 non-null float64\n",
      "YEARS_BUILD_MODE                10745 non-null float64\n",
      "COMMONAREA_MODE                 10745 non-null float64\n",
      "ELEVATORS_MODE                  10745 non-null float64\n",
      "ENTRANCES_MODE                  10745 non-null float64\n",
      "FLOORSMAX_MODE                  10745 non-null float64\n",
      "FLOORSMIN_MODE                  10745 non-null float64\n",
      "LANDAREA_MODE                   10745 non-null float64\n",
      "LIVINGAPARTMENTS_MODE           10745 non-null float64\n",
      "LIVINGAREA_MODE                 10745 non-null float64\n",
      "NONLIVINGAPARTMENTS_MODE        10745 non-null float64\n",
      "NONLIVINGAREA_MODE              10745 non-null float64\n",
      "APARTMENTS_MEDI                 10745 non-null float64\n",
      "BASEMENTAREA_MEDI               10745 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MEDI    10745 non-null float64\n",
      "YEARS_BUILD_MEDI                10745 non-null float64\n",
      "COMMONAREA_MEDI                 10745 non-null float64\n",
      "ELEVATORS_MEDI                  10745 non-null float64\n",
      "ENTRANCES_MEDI                  10745 non-null float64\n",
      "FLOORSMAX_MEDI                  10745 non-null float64\n",
      "FLOORSMIN_MEDI                  10745 non-null float64\n",
      "LANDAREA_MEDI                   10745 non-null float64\n",
      "LIVINGAPARTMENTS_MEDI           10745 non-null float64\n",
      "LIVINGAREA_MEDI                 10745 non-null float64\n",
      "NONLIVINGAPARTMENTS_MEDI        10745 non-null float64\n",
      "NONLIVINGAREA_MEDI              10745 non-null float64\n",
      "TOTALAREA_MODE                  10745 non-null float64\n",
      "OBS_30_CNT_SOCIAL_CIRCLE        10745 non-null float64\n",
      "DEF_30_CNT_SOCIAL_CIRCLE        10745 non-null float64\n",
      "OBS_60_CNT_SOCIAL_CIRCLE        10745 non-null float64\n",
      "DEF_60_CNT_SOCIAL_CIRCLE        10745 non-null float64\n",
      "DAYS_LAST_PHONE_CHANGE          10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR      10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_DAY       10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK      10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON       10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_QRT       10745 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR      10745 non-null float64\n",
      "dtypes: float64(66), int64(14)\n",
      "memory usage: 6.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Version with no null values and categorical features.\n",
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = drop_features(input_df, categorical_feats + bool_feats)\n",
    "input_df = input_df.dropna()\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 2_b: With categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8602 entries, 71 to 307482\n",
      "Columns: 251 entries, SK_ID_CURR to EMERGENCYSTATE_MODE_nan\n",
      "dtypes: float64(66), int64(185)\n",
      "memory usage: 16.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = input_df.dropna()\n",
    "\n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64, dummy_na= True)\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 2_c: With categorical features WOE Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8602 entries, 71 to 307482\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(82), int64(40)\n",
      "memory usage: 8.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = input_df.dropna()\n",
    "\n",
    "for cat_feature in categorical_feats:\n",
    "    WoE_df = calculate_WOE(input_df, 'TARGET', cat_feature)\n",
    "    input_df[cat_feature] = input_df[cat_feature].replace(WoE_df.set_index('Value')['WoE'])\n",
    "\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats, WoE_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set version 3: With missing values imputed\n",
    "### Data set version 3_a: Without categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307507 entries, 0 to 307510\n",
      "Data columns (total 80 columns):\n",
      "SK_ID_CURR                      307507 non-null int64\n",
      "TARGET                          307507 non-null int64\n",
      "CNT_CHILDREN                    307507 non-null float64\n",
      "AMT_INCOME_TOTAL                307507 non-null float64\n",
      "AMT_CREDIT                      307507 non-null float64\n",
      "AMT_ANNUITY                     307507 non-null float64\n",
      "AMT_GOODS_PRICE                 307507 non-null float64\n",
      "REGION_POPULATION_RELATIVE      307507 non-null float64\n",
      "DAYS_BIRTH                      307507 non-null float64\n",
      "DAYS_EMPLOYED                   307507 non-null float64\n",
      "DAYS_REGISTRATION               307507 non-null float64\n",
      "DAYS_ID_PUBLISH                 307507 non-null float64\n",
      "OWN_CAR_AGE                     307507 non-null float64\n",
      "CNT_FAM_MEMBERS                 307507 non-null float64\n",
      "REGION_RATING_CLIENT            307507 non-null float64\n",
      "REGION_RATING_CLIENT_W_CITY     307507 non-null float64\n",
      "HOUR_APPR_PROCESS_START         307507 non-null float64\n",
      "REG_REGION_NOT_LIVE_REGION      307507 non-null float64\n",
      "REG_REGION_NOT_WORK_REGION      307507 non-null float64\n",
      "LIVE_REGION_NOT_WORK_REGION     307507 non-null float64\n",
      "REG_CITY_NOT_LIVE_CITY          307507 non-null float64\n",
      "REG_CITY_NOT_WORK_CITY          307507 non-null float64\n",
      "LIVE_CITY_NOT_WORK_CITY         307507 non-null float64\n",
      "EXT_SOURCE_1                    307507 non-null float64\n",
      "EXT_SOURCE_2                    307507 non-null float64\n",
      "EXT_SOURCE_3                    307507 non-null float64\n",
      "APARTMENTS_AVG                  307507 non-null float64\n",
      "BASEMENTAREA_AVG                307507 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_AVG     307507 non-null float64\n",
      "YEARS_BUILD_AVG                 307507 non-null float64\n",
      "COMMONAREA_AVG                  307507 non-null float64\n",
      "ELEVATORS_AVG                   307507 non-null float64\n",
      "ENTRANCES_AVG                   307507 non-null float64\n",
      "FLOORSMAX_AVG                   307507 non-null float64\n",
      "FLOORSMIN_AVG                   307507 non-null float64\n",
      "LANDAREA_AVG                    307507 non-null float64\n",
      "LIVINGAPARTMENTS_AVG            307507 non-null float64\n",
      "LIVINGAREA_AVG                  307507 non-null float64\n",
      "NONLIVINGAPARTMENTS_AVG         307507 non-null float64\n",
      "NONLIVINGAREA_AVG               307507 non-null float64\n",
      "APARTMENTS_MODE                 307507 non-null float64\n",
      "BASEMENTAREA_MODE               307507 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MODE    307507 non-null float64\n",
      "YEARS_BUILD_MODE                307507 non-null float64\n",
      "COMMONAREA_MODE                 307507 non-null float64\n",
      "ELEVATORS_MODE                  307507 non-null float64\n",
      "ENTRANCES_MODE                  307507 non-null float64\n",
      "FLOORSMAX_MODE                  307507 non-null float64\n",
      "FLOORSMIN_MODE                  307507 non-null float64\n",
      "LANDAREA_MODE                   307507 non-null float64\n",
      "LIVINGAPARTMENTS_MODE           307507 non-null float64\n",
      "LIVINGAREA_MODE                 307507 non-null float64\n",
      "NONLIVINGAPARTMENTS_MODE        307507 non-null float64\n",
      "NONLIVINGAREA_MODE              307507 non-null float64\n",
      "APARTMENTS_MEDI                 307507 non-null float64\n",
      "BASEMENTAREA_MEDI               307507 non-null float64\n",
      "YEARS_BEGINEXPLUATATION_MEDI    307507 non-null float64\n",
      "YEARS_BUILD_MEDI                307507 non-null float64\n",
      "COMMONAREA_MEDI                 307507 non-null float64\n",
      "ELEVATORS_MEDI                  307507 non-null float64\n",
      "ENTRANCES_MEDI                  307507 non-null float64\n",
      "FLOORSMAX_MEDI                  307507 non-null float64\n",
      "FLOORSMIN_MEDI                  307507 non-null float64\n",
      "LANDAREA_MEDI                   307507 non-null float64\n",
      "LIVINGAPARTMENTS_MEDI           307507 non-null float64\n",
      "LIVINGAREA_MEDI                 307507 non-null float64\n",
      "NONLIVINGAPARTMENTS_MEDI        307507 non-null float64\n",
      "NONLIVINGAREA_MEDI              307507 non-null float64\n",
      "TOTALAREA_MODE                  307507 non-null float64\n",
      "OBS_30_CNT_SOCIAL_CIRCLE        307507 non-null float64\n",
      "DEF_30_CNT_SOCIAL_CIRCLE        307507 non-null float64\n",
      "OBS_60_CNT_SOCIAL_CIRCLE        307507 non-null float64\n",
      "DEF_60_CNT_SOCIAL_CIRCLE        307507 non-null float64\n",
      "DAYS_LAST_PHONE_CHANGE          307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR      307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_DAY       307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK      307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON       307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_QRT       307507 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR      307507 non-null float64\n",
      "dtypes: float64(78), int64(2)\n",
      "memory usage: 190.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = drop_features(input_df, categorical_feats + bool_feats)\n",
    "input_df = impute_features(input_df, 'All')\n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 3_b: With categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nominal variables imputed by mode values and Numerical variables imputed by mean\n",
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose = True)\n",
    "    \n",
    "input_df = impute_features(input_df, 'All')\n",
    "    \n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)\n",
    "    \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 3_c: With categorical features WOE encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nominal variables imputed by mode values and Numerical variables imputed by mean\n",
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = impute_features(input_df, 'All')\n",
    "    \n",
    "#Replace categorical columns with WOE columns\n",
    "for cat_feature in categorical_feats:\n",
    "    WoE_df = calculate_WOE(input_df, 'TARGET', cat_feature)\n",
    "    input_df[cat_feature] = input_df[cat_feature].replace(WoE_df.set_index('Value')['WoE'])\n",
    "    del WoE_df\n",
    "    \n",
    "input_df.info()\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 4: Imputed and Scaled Numerical Features\n",
    "### Data set version 4_a: Without categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = drop_features(input_df, categorical_feats + bool_feats)\n",
    "input_df = impute_features(input_df, 'All')\n",
    "input_df = scale_features(input_df, integer_feats + floatingPoint_feats)\n",
    "input_df.info()\n",
    "\n",
    "del input_df, categorical_feats, floatingPoint_feats, bool_feats, integer_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 4_b: With categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose = True)\n",
    "    \n",
    "input_df = impute_features(input_df, 'All')\n",
    "input_df = scale_features(input_df, integer_feats + floatingPoint_feats)\n",
    "    \n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)\n",
    "    \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 4_c: With categorical features WoE Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'])\n",
    "input_df = impute_features(input_df, 'All')\n",
    "input_df = scale_features(input_df, integer_feats + floatingPoint_feats)\n",
    "    \n",
    "#Replace categorical columns with WOE columns\n",
    "for cat_feature in categorical_feats:\n",
    "    WoE_df = calculate_WOE(input_df, 'TARGET', cat_feature)\n",
    "    input_df[cat_feature] = input_df[cat_feature].replace(WoE_df.set_index('Value')['WoE'])\n",
    "    del WoE_df\n",
    "    \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 5: Impute and Scaled Numerical Features with Feature Selection\n",
    "### Data set version 5_a: Without categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "input_df = input_df.drop(columns = 'SK_ID_CURR')\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose=True)\n",
    "labels = input_df.pop('TARGET')\n",
    "\n",
    "input_df = drop_features(input_df, categorical_feats)\n",
    "\n",
    "feature_df = select_features(input_df, labels, min_votes = 4, drop_ratio = 0.5)\n",
    "\n",
    "selected_features = feature_df[feature_df.Total >= 3].Feature.values\n",
    "\n",
    "input_df = input_df[selected_features]\n",
    "input_df = impute_features(input_df, features ='All')    \n",
    "input_df = scale_features(input_df)\n",
    "\n",
    "input_df['TARGET'] = labels \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 5_b: With categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "input_df = input_df.drop(columns = 'SK_ID_CURR')\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose=True)\n",
    "labels = input_df.pop('TARGET')\n",
    "\n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)\n",
    "\n",
    "feature_df = select_features(input_df, labels, min_votes = 4, drop_ratio = 0.5)\n",
    "\n",
    "selected_features = feature_df[feature_df.Total >= 3].Feature.values\n",
    "input_df = input_df[selected_features]\n",
    "\n",
    "input_df = impute_features(input_df, features ='All')    \n",
    "input_df = scale_features(input_df)\n",
    "\n",
    "input_df['TARGET'] = labels \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 5_c: With categorical features WoE Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "input_df = input_df.drop(columns = 'SK_ID_CURR')\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose=True)\n",
    "\n",
    "#Replace categorical columns with WOE columns\n",
    "for cat_feature in categorical_feats:\n",
    "    WoE_df = calculate_WOE(input_df, 'TARGET', cat_feature)\n",
    "    input_df[cat_feature] = input_df[cat_feature].replace(WoE_df.set_index('Value')['WoE'])\n",
    "    del WoE_df\n",
    "    \n",
    "labels = input_df.pop('TARGET')\n",
    "feature_df = select_features(input_df, labels, min_votes = 4, drop_ratio = 0.5)\n",
    "\n",
    "selected_features = feature_df[feature_df.Total >= 3].Feature.values\n",
    "input_df = input_df[selected_features]\n",
    "\n",
    "input_df = impute_features(input_df, features ='All')    \n",
    "input_df = scale_features(input_df)\n",
    "\n",
    "input_df['TARGET'] = labels \n",
    "input_df.info()\n",
    "del input_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 6: Balanced and Imbalanced Sampling\n",
    "### Data set version 6_a: Balanced Samples with categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "input_df = input_df.drop(columns = 'SK_ID_CURR')\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose=True)\n",
    "labels = input_df.pop('TARGET')\n",
    "\n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)\n",
    "\n",
    "input_df = impute_features(input_df, features ='All')    \n",
    "input_df = scale_features(input_df)\n",
    "\n",
    "sampled_df , sampled_labels = take_sample(input_df, labels, stratified = False)\n",
    "sampled_df['TARGET'] = sampled_labels\n",
    "sampled_df.info()\n",
    "del input_df, sampled_df, labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set version 6_b: Unbalanced sample with categorical features OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "input_df = readFile(dataFolder + '\\\\application_train.csv')\n",
    "input_df = replace_outliers(input_df)\n",
    "input_df = input_df.drop(columns = 'SK_ID_CURR')\n",
    "categorical_feats, floatingPoint_feats, bool_feats, integer_feats = identify_feature_types(input_df,\n",
    "                                                                        ['TARGET', 'SK_ID_CURR', 'Unnamed :0'], verbose=True)\n",
    "labels = input_df.pop('TARGET')\n",
    "\n",
    "input_df = pd.get_dummies(input_df, columns=categorical_feats, dtype=np.int64)\n",
    "\n",
    "input_df = impute_features(input_df, features ='All')    \n",
    "input_df = scale_features(input_df)\n",
    "\n",
    "sampled_df , sampled_labels = take_sample(input_df, labels)\n",
    "sampled_df['TARGET'] = sampled_labels\n",
    "sampled_df.info()\n",
    "del input_df, sampled_df, labels\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
