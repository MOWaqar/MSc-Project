{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM\n",
    "### LGBM implementation \n",
    "#### Import Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "#from pandas.tools.plotting import table\n",
    "\n",
    "#memory management\n",
    "import gc\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Logistic regression\n",
    "from lightgbm import LGBMClassifier\n",
    "#to measure ROC AUC performance\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set folder paths for getting input and saving outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set input data folder \n",
    "dataFolder = os.getcwd()+os.sep+os.pardir+os.sep + 'CodeOutputs'\n",
    "if(not os.path.exists(dataFolder)):\n",
    "    print(\"Input Data folder not found. Please specify data folder path as dataFolder variable to proceed\")\n",
    "    raise NotADirectoryError\n",
    "    \n",
    "#Create output folder is it does not exist\n",
    "outputFolder = os.getcwd()+os.sep+os.pardir+os.sep + 'CodeOutputs'\n",
    "\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)\n",
    "    print('Output Folder created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_input(filename):\n",
    "    # Read Training data\n",
    "    df = pd.read_csv(dataFolder + os.sep + filename)\n",
    "    labels = df.pop('TARGET')\n",
    "    if('Unnamed: 0' in df):\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "    \n",
    "    df = df.drop(columns='SK_ID_CURR')\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion that performs 10 fold cv on input data and returns AUC score\n",
    "def LGBM_Classifier(df, labels):\n",
    "    probas_ = np.zeros(df.shape[0])\n",
    "    # Run classifier with cross-validation\n",
    "    cv = KFold(n_splits=10)\n",
    "\n",
    "    for trainSet, testSet in cv.split(df, labels):\n",
    "        clf = LGBMClassifier(n_jobs=-1, silent=True, )\n",
    "        model = clf.fit(df.iloc[trainSet], labels.iloc[trainSet], eval_set=[(df.iloc[trainSet], labels.iloc[trainSet]),\n",
    "            (df.iloc[testSet], labels.iloc[testSet])], eval_metric= 'auc', verbose= False, early_stopping_rounds= 200)\n",
    "        probas_[testSet] = model.predict_proba(df.iloc[testSet], num_iteration=clf.best_iteration_)[:,1]\n",
    "        del clf\n",
    "\n",
    "    return roc_auc_score(labels, probas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: DataSetVersion1_a.csv,  AUC score : 0.742\n",
      "File: DataSetVersion1_b.csv,  AUC score : 0.752\n",
      "File: DataSetVersion1_c.csv,  AUC score : 0.752\n",
      "File: DataSetVersion2_a.csv,  AUC score : 0.746\n",
      "File: DataSetVersion2_b.csv,  AUC score : 0.756\n",
      "File: DataSetVersion2_c.csv,  AUC score : 0.756\n",
      "File: DataSetVersion3_a.csv,  AUC score : 0.746\n",
      "File: DataSetVersion3_b.csv,  AUC score : 0.751\n",
      "File: DataSetVersion3_c.csv,  AUC score : 0.752\n"
     ]
    }
   ],
   "source": [
    "file_names = ['DataSetVersion1_a.csv', 'DataSetVersion1_b.csv', 'DataSetVersion1_c.csv', 'DataSetVersion2_a.csv',\n",
    "              'DataSetVersion2_b.csv', 'DataSetVersion2_c.csv', 'DataSetVersion3_a.csv', 'DataSetVersion3_b.csv',\n",
    "             'DataSetVersion3_c.csv']\n",
    "\n",
    "for filename in file_names:\n",
    "    input_df, labels = setup_input(filename)\n",
    "    try:\n",
    "        print('File: {},  AUC score : {:0.3f}'.format(filename,LGBM_Classifier(input_df, labels)))\n",
    "        del input_df,labels\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print('Classifier could not run on the data set. Put X instead of score.')\n",
    "        del input_df,labels\n",
    "        gc.collect()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['DataSetVersion4_a.csv', 'DataSetVersion4_b.csv', 'DataSetVersion4_c.csv']\n",
    "\n",
    "for filename in file_names:\n",
    "    input_df, labels = setup_input(filename)\n",
    "    try:\n",
    "        print('File: {},  AUC score : {:0.3f}'.format(filename,LGBM_Classifier(input_df, labels)))\n",
    "        del input_df,labels\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print('Classifier could not run on the data set. Put X instead of score.')\n",
    "        del input_df,labels\n",
    "        gc.collect()\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
